import { GoogleGenAI, Modality } from "@google/genai";
import { supabase } from "./supabase";

/**
 * SERVI√áO DE IA UNIFICADO - GEMINI & GROQ
 * Suporta m√∫ltiplos provedores de IA com fallback autom√°tico e sele√ß√£o manual
 */

export type AIProvider = 'gemini' | 'groq';

interface AIConfig {
  provider: AIProvider;
  apiKey: string;
}

export interface AIStreamCallback {
  onChunk: (text: string) => void;
  onComplete: () => void;
  onError: (error: Error) => void;
}

/**
 * Processa erros de API de IA e retorna uma mensagem amig√°vel.
 */
const processAIError = (error: any, provider: 'Gemini' | 'Groq'): Error => {
  console.error(`Erro no ${provider}:`, error);
  let friendlyMessage = error.message || `Erro desconhecido na API ${provider}`;

  if (typeof friendlyMessage === 'string') {
    if (provider === 'Gemini' && (friendlyMessage.includes('API key expired') || friendlyMessage.includes('API_KEY_INVALID'))) {
      friendlyMessage = `Sua chave de API do Gemini expirou ou √© inv√°lida. Por favor, v√° em Configurar > Sistema & API para atualizar sua chave.`;
    }
    if (provider === 'Groq' && friendlyMessage.includes('invalid_api_key')) {
      friendlyMessage = `Sua chave de API do Groq √© inv√°lida. Por favor, v√° em Configurar > Sistema & API para atualizar sua chave.`;
    }
  }

  return new Error(`${provider} Error: ${friendlyMessage}`);
};

/**
 * Detecta qual provedor de IA usar baseado nas chaves dispon√≠veis
 */
export const detectAIProvider = (
  geminiKey?: string,
  groqKey?: string,
  preferredProvider?: AIProvider
): AIConfig | null => {
  // Se houver prefer√™ncia expl√≠cita e a chave estiver dispon√≠vel
  if (preferredProvider === 'gemini' && geminiKey && geminiKey.length > 10) {
    return { provider: 'gemini', apiKey: geminiKey };
  }

  if (preferredProvider === 'groq' && groqKey && groqKey.length > 10) {
    return { provider: 'groq', apiKey: groqKey };
  }

  // Fallback autom√°tico baseado nas chaves dispon√≠veis
  if (geminiKey && geminiKey.length > 10) {
    return { provider: 'gemini', apiKey: geminiKey };
  }

  if (groqKey && groqKey.length > 10) {
    return { provider: 'groq', apiKey: groqKey };
  }

  return null;
};

/**
 * Streaming com Gemini (via SDK Oficial @google/genai)
 */
const streamWithGemini = async (
  apiKey: string,
  prompt: string,
  callbacks: AIStreamCallback,
  context: 'flashcard' | 'general' = 'general'
): Promise<void> => {
  const models = ['gemini-2.0-flash', 'gemini-1.5-flash', 'gemini-1.5-pro'];
  let lastError: any = null;

  // Prompts sincronizados com o snippet do usu√°rio
  const flashcardPrompt = `Voc√™ √© um tutor de concursos. Explique o conceito, d√™ um exemplo, e crie um mnem√¥nico para o flashcard a seguir:\n\n${prompt}`;
  const generalPrompt = `Voc√™ √© um professor universit√°rio especialista em concursos p√∫blicos, conhecido por sua did√°tica e profundidade. Sua resposta DEVE ser estruturada em Markdown com os seguintes t√≥picos:\n- **# Explica√ß√£o Detalhada:** Elabore o conceito com profundidade.\n- **# Exemplo Pr√°tico Aprofundado:** Forne√ßa um exemplo pr√°tico bem detalhado.`;
  const finalPrompt = context === 'flashcard' ? flashcardPrompt : `${generalPrompt}\n\nConte√∫do: ${prompt}`;

  for (const modelId of models) {
    try {
      console.log(`ü§ñ Tentando streaming Gemini SDK (${modelId}) para ${context}...`);
      const ai = new GoogleGenAI({ apiKey });

      const result = await ai.models.generateContentStream({
        model: modelId,
        contents: [{ role: 'user', parts: [{ text: finalPrompt }] }],
        config: {
          temperature: 0.7,
          maxOutputTokens: 2048,
        }
      });

      for await (const chunk of result) {
        const text = chunk.text;
        if (text) {
          callbacks.onChunk(text);
        }
      }

      console.log(`‚úÖ Streaming Gemini (${modelId}) completo`);
      callbacks.onComplete();
      return;
    } catch (error: any) {
      lastError = error;
      console.warn(`‚ö†Ô∏è Falha no modelo ${modelId}:`, error.message);
      // Se for erro de autentica√ß√£o ou cota, n√£o adianta trocar modelo
      if (error.message?.includes('API_KEY') || error.message?.includes('quota')) break;
    }
  }

  callbacks.onError(processAIError(lastError, 'Gemini'));
};

/**
 * Streaming com Groq (via REST API)
 */
const streamWithGroq = async (
  apiKey: string,
  prompt: string,
  callbacks: AIStreamCallback
): Promise<void> => {
  try {
    console.log('üöÄ Iniciando streaming com Groq...');

    const systemPrompt = `Voc√™ √© um professor universit√°rio especialista em concursos p√∫blicos, conhecido por sua did√°tica e profundidade. Sua resposta DEVE ser estruturada em Markdown com os seguintes t√≥picos:\n- **# Explica√ß√£o Detalhada:** Elabore o conceito com profundidade, conectando com outros temas relevantes.\n- **# Exemplo Pr√°tico Aprofundado:** Forne√ßa um exemplo pr√°tico bem detalhado, com contexto e explicando passo a passo a aplica√ß√£o do conceito. Se poss√≠vel, use um cen√°rio de concurso p√∫blico.`;

    const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'llama-3.3-70b-versatile',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: `Analise o seguinte conte√∫do:\n\n${prompt}` }
        ],
        temperature: 0.5,
        max_tokens: 4096,
        stream: true,
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Groq API error: ${response.status}`);
    }

    const reader = response.body?.getReader();
    if (!reader) throw new Error('No response body from Groq');

    const decoder = new TextDecoder();
    let buffer = '';

    try {
      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        buffer += decoder.decode(value, { stream: true });
        const lines = buffer.split('\n');
        buffer = lines.pop() || '';

        for (const line of lines) {
          const trimmed = line.trim();
          if (!trimmed || trimmed === 'data: [DONE]') continue;

          if (trimmed.startsWith('data: ')) {
            try {
              const json = JSON.parse(trimmed.slice(6));
              const content = json.choices?.[0]?.delta?.content;
              if (content) {
                callbacks.onChunk(content);
              }
            } catch (e) {
              console.warn('Failed to parse Groq chunk:', e);
            }
          }
        }
      }
    } finally {
      reader.releaseLock();
    }

    console.log('‚úÖ Streaming Groq completo');
    callbacks.onComplete();
  } catch (error: any) {
    callbacks.onError(processAIError(error, 'Groq'));
  }
};

/**
 * Fun√ß√£o principal de streaming
 */
export const streamAIContent = async (
  prompt: string,
  callbacks: AIStreamCallback,
  geminiKey?: string,
  groqKey?: string,
  preferredProvider?: AIProvider
): Promise<void> => {
  const config = detectAIProvider(geminiKey, groqKey, preferredProvider);

  if (!config) {
    const error = new Error('Nenhuma chave de IA configurada. Configure Gemini ou Groq nas configura√ß√µes.');
    callbacks.onError(error);
    return;
  }

  try {
    if (config.provider === 'gemini') {
      try {
        const isFlashcard = prompt.toLowerCase().includes('flashcard') || prompt.toLowerCase().includes('mnem√¥nico');
        await streamWithGemini(config.apiKey, prompt, callbacks, isFlashcard ? 'flashcard' : 'general');
      } catch (err: any) {
        console.error("üî¥ Falha cr√≠tica no Gemini:", err);
        // Fallback para Groq se Gemini falhar
        if (groqKey && groqKey.length > 10) {
          callbacks.onChunk(`\n\nüîÑ [Aviso: Gemini falhou (${err.message}). Ativando Groq automaticamente...]\n\n`);
          await streamWithGroq(groqKey, prompt, callbacks);
        } else {
          throw err;
        }
      }
    } else {
      try {
        await streamWithGroq(config.apiKey, prompt, callbacks);
      } catch (err: any) {
        // Fallback para Gemini se Groq falhar
        if (geminiKey && geminiKey.length > 10) {
          callbacks.onChunk("\n\nüîÑ [Aviso: Groq falhou. Ativando Gemini automaticamente...]\n\n");
          await streamWithGemini(geminiKey, prompt, callbacks);
        } else {
          throw err;
        }
      }
    }
  } catch (error) {
    callbacks.onError(error as Error);
  }
};

/**
 * Gera√ß√£o sem streaming (fallback)
 */
export const generateAIContent = async (
  prompt: string,
  geminiKey?: string,
  groqKey?: string,
  preferredProvider?: AIProvider,
  context: 'flashcard' | 'general' | 'mapa' | 'tabela' | 'fluxo' | 'info' = 'general'
): Promise<string> => {
  const config = detectAIProvider(geminiKey, groqKey, preferredProvider);

  if (!config) {
    throw new Error('Nenhuma chave de IA configurada');
  }

  const runGemini = async (key: string) => {
    const models = ['gemini-2.0-flash', 'gemini-1.5-flash', 'gemini-1.5-pro'];
    let lastError: any = null;

    let finalPrompt = "";

    if (context === 'flashcard') {
      finalPrompt = `Voc√™ √© um tutor de concursos. Explique o conceito, d√™ um exemplo, e crie um mnem√¥nico/m√∫sica curta para o flashcard a seguir:\n\n${prompt}`;
    } else if (context === 'mapa') {
      finalPrompt = `Voc√™ √© um especialista em mapas mentais pedag√≥gicos. Crie um MAPA MENTAL ESTRUTURADO sobre: ${prompt}.
      Use a seguinte sintaxe Markdown rigorosa:
      # [T√çTULO CENTRAL]
      ## [RAMO PRINCIPAL]
      ### [SUB-T√ìPICO]
      - [DETALHE]
      
      Regras:
      1. Use no m√°ximo 4 n√≠veis de profundidade.
      2. Mantenha os termos curtos e impactantes.
      3. Seja extremamente minucioso na l√≥gica jur√≠dica/t√©cnica.`;
    } else if (context === 'tabela') {
      finalPrompt = `Voc√™ √© um mestre em did√°tica e s√≠ntese. Crie uma TABELA COMPARATIVA t√©cnica sobre: ${prompt}.
      
      REGRAS DE OURO:
      1. N√ÉO adicione nenhum texto introdut√≥rio ou conclusivo. Responda APENAS com a tabela em Markdown.
      2. Use exatamente 3 colunas: | Crit√©rio | Conceito Principal | Comparativo/Oposto |
      3. Seja rigoroso nos termos e use de 4 a 6 linhas de compara√ß√£o.
      
      Exemplo de Sa√≠da:
      | Crit√©rio | Conceito Principal | Comparativo/Oposto |
      |---|---|---|
      | Defini√ß√£o | Texto... | Texto... |
      | Fundamento | Texto... | Texto... |`;
    } else if (context === 'fluxo') {
      finalPrompt = `Voc√™ √© um analista de processos e l√≥gica jur√≠dica. Gere um FLUXOGRAMA L√ìGICO VERTICAL para explicar: ${prompt}.
      Use obrigatoriamente as seguintes tags para cada etapa:
      [IN√çCIO] -> Breve introdu√ß√£o.
      [A√á√ÉO] -> Procedimento ou fato.
      [DECIS√ÉO] -> Pergunta ou bifurca√ß√£o.
      [RESULTADO] -> Conseq√º√™ncia de uma a√ß√£o/decis√£o.
      [FIM] -> Conclus√£o.
      
      Exemplo de Sa√≠da:
      1. [IN√çCIO] Texto
      2. [DECIS√ÉO] Texto?
      3. [RESULTADO] Texto
      
      Regras:
      - Seja anal√≠tico.
      - Use l√≥gica de causa e efeito clara.`;
    } else if (context === 'info') {
      finalPrompt = `Crie um INFOGR√ÅFICO RESUMIDO em texto (Cheat Sheet) sobre: ${prompt}. 
      Use MUITOS EMOJIS relevantes, T√çTULOS EM MAI√öSCULAS e Bullet Points. 
      Organize em se√ß√µes como: üìå DEFINI√á√ÉO, ‚ö° PONTOS CHAVE, ‚ö†Ô∏è PEGADINHAS DE PROVA. 
      Use Markdown para dar um visual premium.`;
    } else {
      finalPrompt = `Voc√™ √© um professor universit√°rio especialista em concursos p√∫blicos, conhecido por sua did√°tica e profundidade. Sua resposta DEVE ser estruturada em Markdown com os seguintes t√≥picos:\n- **# Explica√ß√£o Detalhada:** Elabore o conceito com profundidade.\n- **# Exemplo Pr√°tico Aprofundado:** Forne√ßa um exemplo pr√°tico bem detalhado.\n\nConte√∫do: ${prompt}`;
    }

    for (const modelId of models) {
      try {
        const ai = new GoogleGenAI({ apiKey: key });
        const response = await ai.models.generateContent({
          model: modelId,
          contents: [{ role: 'user', parts: [{ text: finalPrompt }] }],
          config: {
            temperature: 0.7,
            maxOutputTokens: 2048,
          }
        }) as any;

        // Extra√ß√£o robusta de texto (compatibilidade com m√∫ltiplos padr√µes de SDK)
        let resultText = "";
        try {
          if (typeof response.text === 'function') {
            resultText = response.text();
          } else if (response.response && typeof response.response.text === 'function') {
            resultText = response.response.text();
          } else if (typeof response.text === 'string') {
            resultText = response.text;
          } else if (response.candidates?.[0]?.content?.parts?.[0]?.text) {
            resultText = response.candidates[0].content.parts[0].text;
          }
        } catch (e) {
          console.warn("Falha na extra√ß√£o refinada do texto Gemini:", e);
        }

        return resultText || '';
      } catch (error: any) {
        lastError = error;
        if (error.message?.includes('API_KEY')) break;
      }
    }
    throw processAIError(lastError, 'Gemini');
  };

  const runGroq = async (key: string) => {
    try {
      const systemPrompt = `Voc√™ √© um professor universit√°rio especialista em concursos p√∫blicos, conhecido por sua did√°tica e profundidade.Sua resposta DEVE ser estruturada em Markdown com os seguintes t√≥picos: \n - **# Explica√ß√£o Detalhada:** Elabore o conceito com profundidade, conectando com outros temas relevantes.\n - **# Exemplo Pr√°tico Aprofundado:** Forne√ßa um exemplo pr√°tico bem detalhado, com contexto e explicando passo a passo a aplica√ß√£o do conceito.Se poss√≠vel, use um cen√°rio de concurso p√∫blico.`;
      const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${key} `,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'llama-3.3-70b-versatile',
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: `Contexto: ${context} \nAn√°lise: ${prompt} ` }
          ],
          temperature: 0.5,
          max_tokens: 4096,
        }),
      });

      if (!response.ok) throw new Error(`Groq status ${response.status} `);
      const data = await response.json();
      return data.choices[0].message.content;
    } catch (error: any) {
      throw processAIError(error, 'Groq');
    }
  };

  try {
    if (config.provider === 'gemini') {
      try {
        return await runGemini(config.apiKey);
      } catch (err) {
        if (groqKey && groqKey.length > 10) return await runGroq(groqKey);
        throw err;
      }
    } else {
      try {
        return await runGroq(config.apiKey);
      } catch (err) {
        if (geminiKey && geminiKey.length > 10) return await runGemini(geminiKey);
        throw err;
      }
    }
  } catch (err: any) {
    throw err;
  }
};

// --- √ÅUDIO / TTS (Podcast Style) ---

function decodeBase64(base64: string) {
  const binaryString = atob(base64);
  const len = binaryString.length;
  const bytes = new Uint8Array(len);
  for (let i = 0; i < len; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes;
}

async function decodeAudioData(
  data: Uint8Array,
  ctx: AudioContext,
  sampleRate: number = 24000,
  numChannels: number = 1,
): Promise<AudioBuffer> {
  const dataInt16 = new Int16Array(data.buffer);
  const frameCount = dataInt16.length / numChannels;
  const buffer = ctx.createBuffer(numChannels, frameCount, sampleRate);

  for (let channel = 0; channel < numChannels; channel++) {
    const channelData = buffer.getChannelData(channel);
    for (let i = 0; i < frameCount; i++) {
      channelData[i] = dataInt16[i * numChannels + channel] / 32768.0;
    }
  }
  return buffer;
}

function createWavFile(samples: Int16Array, sampleRate: number = 24000): Blob {
  const buffer = new ArrayBuffer(44 + samples.length * 2);
  const view = new DataView(buffer);

  const writeString = (view: DataView, offset: number, string: string) => {
    for (let i = 0; i < string.length; i++) {
      view.setUint8(offset + i, string.charCodeAt(i));
    }
  };

  writeString(view, 0, 'RIFF');
  view.setUint32(4, 36 + samples.length * 2, true);
  writeString(view, 8, 'WAVE');
  writeString(view, 12, 'fmt ');
  view.setUint32(16, 16, true);
  view.setUint16(20, 1, true);
  view.setUint16(22, 1, true);
  view.setUint32(24, sampleRate, true);
  view.setUint32(28, sampleRate * 2, true);
  view.setUint16(32, 2, true);
  view.setUint16(34, 16, true);
  writeString(view, 36, 'data');
  view.setUint32(40, samples.length * 2, true);

  let offset = 44;
  for (let i = 0; i < samples.length; i++) {
    view.setInt16(offset, samples[i], true);
    offset += 2;
  }

  return new Blob([view], { type: 'audio/wav' });
}

export const handlePlayRevisionAudio = async (
  text: string,
  revisionId: string,
  apiKey: string,
  onStart: () => void,
  onEnd: () => void,
  onError: (err: string) => void
): Promise<() => void> => {
  let audioContext: AudioContext | null = null;
  let source: AudioBufferSourceNode | null = null;
  let htmlAudio: HTMLAudioElement | null = null;

  try {
    const fileName = `${revisionId}.wav`;
    const bucketName = 'audio-revisions';

    let cacheExists = false;
    try {
      const { data: listData } = await supabase.storage.from(bucketName).list('', { search: fileName });
      if (listData && listData.length > 0) cacheExists = true;
    } catch (e) { console.warn("Erro cache:", e); }

    if (cacheExists) {
      const { data: publicUrlData } = supabase.storage.from(bucketName).getPublicUrl(fileName);
      const publicUrl = publicUrlData?.publicUrl;
      if (publicUrl) {
        htmlAudio = new Audio(publicUrl);
        htmlAudio.onended = () => onEnd();
        onStart();
        htmlAudio.play().catch(e => onError("Erro reprodu√ß√£o cache."));
        return () => { if (htmlAudio) htmlAudio.pause(); };
      }
    }

    console.log("üéôÔ∏è √Åudio elite (v2.5 TTS)...");
    const ai = new GoogleGenAI({ apiKey });
    const response = await ai.models.generateContent({
      model: "gemini-2.0-flash", // Nome atualizado
      contents: [{ parts: [{ text: text.substring(0, 4000) }] }],
      config: {
        responseModalities: [Modality.AUDIO],
        speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: 'Kore' } } },
      },
    });

    const base64Audio = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
    if (!base64Audio) throw new Error("Audio generation failed");

    audioContext = new (window.AudioContext || (window as any).webkitAudioContext)({ sampleRate: 24000 });
    const audioBytes = decodeBase64(base64Audio);
    const audioBuffer = await decodeAudioData(audioBytes, audioContext);
    source = audioContext.createBufferSource();
    source.buffer = audioBuffer;
    source.connect(audioContext.destination);
    source.onended = () => { onEnd(); audioContext?.close(); };
    onStart();
    source.start();

    // Cache em background
    (async () => {
      try {
        const wavBlob = createWavFile(new Int16Array(audioBytes.buffer), 24000);
        await supabase.storage.from(bucketName).upload(fileName, wavBlob, { contentType: 'audio/wav', upsert: true });
      } catch (e) { }
    })();

    return () => { if (source) source.stop(); if (audioContext) audioContext.close(); };
  } catch (error: any) {
    onError(processAIError(error, 'Gemini').message);
    onEnd();
    return () => { };
  }
};

export const deleteCachedAudio = async (revisionId: string) => {
  const bucketName = 'audio-revisions';
  try {
    await supabase.storage.from(bucketName).remove([`${revisionId}.wav`, `${revisionId} _podcast.wav`]);
  } catch (e) { }
};

export const generatePodcastAudio = async (
  originalText: string,
  referenceId: string,
  apiKey: string,
  onStatusChange: (status: string) => void,
  onStartAudio: () => void,
  onEndAudio: () => void,
  onError: (err: string) => void
): Promise<() => void> => {
  let audioContext: AudioContext | null = null;
  let source: AudioBufferSourceNode | null = null;

  try {
    const fileName = `${referenceId} _podcast.wav`;
    const bucketName = 'audio-revisions';

    // Verifica√ß√£o de cache simplificada
    onStatusChange("Buscando cache...");
    const { data: listData } = await supabase.storage.from(bucketName).list('', { search: fileName });
    if (listData && listData.length > 0) {
      const { data: publicUrlData } = supabase.storage.from(bucketName).getPublicUrl(fileName);
      if (publicUrlData?.publicUrl) {
        const htmlAudio = new Audio(publicUrlData.publicUrl);
        htmlAudio.onended = () => onEndAudio();
        onStartAudio();
        htmlAudio.play().catch(e => onError("Erro ao tocar podcast."));
        return () => { htmlAudio.pause(); };
      }
    }

    const ai = new GoogleGenAI({ apiKey });
    onStatusChange("Escrevendo roteiro...");
    const scriptPrompt = `Converta o seguinte texto em um di√°logo de podcast curto entre Alex e Bia.Formato estrito: Alex: [fala] Bia: [fala].Texto: "${originalText.substring(0, 3000)}"`;
    const scriptResponse = await ai.models.generateContent({
      model: 'gemini-1.5-flash',
      contents: [{ role: 'user', parts: [{ text: scriptPrompt }] }]
    });
    const scriptText = scriptResponse.text || '';

    onStatusChange("Gravando Dual Podcast (Gemini 2.5 TTS)...");
    const audioResponse = await ai.models.generateContent({
      model: "gemini-2.0-flash", // Nome atualizado
      contents: [{ parts: [{ text: scriptText }] }],
      config: {
        responseModalities: [Modality.AUDIO],
        speechConfig: {
          multiSpeakerVoiceConfig: {
            speakerVoiceConfigs: [
              { speaker: 'Alex', voiceConfig: { prebuiltVoiceConfig: { voiceName: 'Fenrir' } } },
              { speaker: 'Bia', voiceConfig: { prebuiltVoiceConfig: { voiceName: 'Kore' } } }
            ]
          }
        }
      }
    });

    const base64Audio = audioResponse.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
    if (!base64Audio) throw new Error("Podcast generation failed");

    onStatusChange("Reproduzindo...");
    audioContext = new (window.AudioContext || (window as any).webkitAudioContext)({ sampleRate: 24000 });
    const audioBytes = decodeBase64(base64Audio);
    const audioBuffer = await decodeAudioData(audioBytes, audioContext);
    source = audioContext.createBufferSource();
    source.buffer = audioBuffer;
    source.connect(audioContext.destination);
    source.onended = () => { onEndAudio(); audioContext?.close(); };
    onStartAudio();
    source.start();

    // Cache background
    (async () => {
      try {
        const wavBlob = createWavFile(new Int16Array(audioBytes.buffer), 24000);
        await supabase.storage.from(bucketName).upload(fileName, wavBlob, { contentType: 'audio/wav', upsert: true });
      } catch (e) { }
    })();

    return () => { if (source) source.stop(); if (audioContext) audioContext.close(); };
  } catch (error: any) {
    onError(processAIError(error, 'Gemini').message);
    onEndAudio();
    return () => { };
  }
};